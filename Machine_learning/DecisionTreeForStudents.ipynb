{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "class DNode:\n",
    "    \"\"\"Class for an internal node of a decision tree\"\"\"\n",
    "    def __init__(self,exs,attributes,possibleVals,targetColName):\n",
    "        self.__availableAttributes = attributes\n",
    "        self.__attribute = ''\n",
    "        self.__examples = exs\n",
    "        self.__colValues = possibleVals\n",
    "        self.__targetCol = targetColName\n",
    "        self.__childNodes = {}\n",
    "        \n",
    "        \n",
    "    def entropy(self,df):\n",
    "        individEnt = 0.0\n",
    "        totalEnt = 0.0\n",
    "        #loop through target column vals\n",
    "        for x in self.__colValues[self.__targetCol]:\n",
    "            #where df target col val = the target col val, add onto exList\n",
    "            exList = df[df[self.__targetCol] == x]\n",
    "            #print exList\n",
    "            #find length of exList\n",
    "            #find length of df\n",
    "            \n",
    "            length1 = float(len(exList))\n",
    "            length2 = float(len(df))\n",
    "            #print length2\n",
    "            if length2 == 0.0:\n",
    "                length2 = 0.00001\n",
    "            div = length1/length2\n",
    "            #print div\n",
    "            \n",
    "            if div == 0:\n",
    "                individEnt = 0\n",
    "            else:\n",
    "                individEnt = -div*math.log(div,2)\n",
    "                \n",
    "            totalEnt += individEnt\n",
    "        #print totalEnt\n",
    "        return totalEnt\n",
    "        \n",
    "    def chooseAttribute(self): \n",
    "        \n",
    "        minEnt = 100000000.0\n",
    "        maxInfo = -100000000.0\n",
    "        \n",
    "        #self.__attribute = random.choice(self.__availableAttributes) #what a terrible way to choose the attribute!\n",
    "        \n",
    "        #first calculate entropy -- say good and vgood are T, acc and unacc are F??\n",
    "        #get the attribute it is, then find the child nodes, then classify good/vgood as T and acc/unacc as F\n",
    "        #print self.__examples[self.__targetCol]\n",
    "        #loop through attributes\n",
    "        a = ''\n",
    "        for attr in self.__availableAttributes:\n",
    "            #print self.__colValues[attr]\n",
    "            #know possible values, now loop through them\n",
    "            for individVal in self.__colValues[attr]:\n",
    "                totalEnt = 0.0\n",
    "                #find examples that have individual value\n",
    "                examps = self.__examples[self.__examples[attr] == individVal]\n",
    "                #print examples[attr]\n",
    "                #compute the entropy now\n",
    "                length = len(examps[attr])\n",
    "                prelimEnt = self.entropy(examps)\n",
    "                #print examples\n",
    "                \n",
    "                #make another function that computes entropy -- done\n",
    "                length1 = float(len(examps))\n",
    "                length2 = float(len(self.__examples))\n",
    "                #print length2\n",
    "                div = length1/length2\n",
    "                \n",
    "                tallyEnt = div*prelimEnt\n",
    "                \n",
    "                totalEnt += tallyEnt \n",
    "            #find the minimum entropy (inside first for loop)\n",
    "            if totalEnt < minEnt:\n",
    "                minEnt = totalEnt\n",
    "            #find out infogain\n",
    "            exs = self.__examples\n",
    "            expectedEntropy = self.entropy(exs)\n",
    "            infoGain = expectedEntropy - minEnt\n",
    "            #find maximum infoGain\n",
    "            if infoGain > maxInfo:\n",
    "                maxInfo = infoGain\n",
    "                a = attr\n",
    "        \n",
    "        #print infoGain\n",
    "        self.__attribute = a\n",
    "      \n",
    "    def train(self):\n",
    "        \"\"\"recursively builds the tree from the training data in __examples\"\"\"\n",
    "        self.chooseAttribute() #'best' attribute at this node\n",
    "\n",
    "        for v in self.__colValues[self.__attribute]: #going through all possible values this attribute can have\n",
    "            exsForChild = self.__examples[self.__examples[self.__attribute] == v] #the subset of examples with the given value v\n",
    "            \n",
    "            if exsForChild.empty: #if there are no examples to pass to this child,\n",
    "                                    #make a leaf with the most common among those \n",
    "                                    #at this node\n",
    "                leafChild = DLeaf( self.__examples[self.__targetCol].value_counts().idxmax() )\n",
    "                self.__childNodes[v] = leafChild #put the leaf in the dictionary of children nodes\n",
    "                \n",
    "            elif len(exsForChild[self.__targetCol].unique()) == 1: #all child examples have same class\n",
    "                leafChild = DLeaf( exsForChild[self.__targetCol].unique()[0] ) #make leaf with that class\n",
    "                self.__childNodes[v] = leafChild #put the leaf in the dictionary of children nodes\n",
    "                \n",
    "            else: #we have a regular decision node for this attribute value\n",
    "                attributesForChild = list(self.__availableAttributes) #copy attributes\n",
    "                attributesForChild.remove(self.__attribute) #remove the one we used at this node\n",
    "                newChild = DNode(exsForChild,attributesForChild,self.__colValues,self.__targetCol)\n",
    "                newChild.train() #generate the rest of the subtree for this child\n",
    "                self.__childNodes[v] = newChild #put the new child node in the dictionary of children nodes\n",
    "            \n",
    "\n",
    "    def printNode(self,numIndents = 0):\n",
    "        \"\"\"display the tree - this isn't the prettiest representation\"\"\"\n",
    "        for i in range(numIndents): print(\" \"), #print with no newline, this only works for Python 2\n",
    "        print(self.__attribute)\n",
    "        for attr in self.__childNodes.keys():\n",
    "            for i in range(numIndents): print(\"|\"),\n",
    "            print(\":\"+attr)\n",
    "            self.__childNodes[attr].printNode(numIndents+1)\n",
    "      \n",
    "    #follows the tree that's already been created\n",
    "    #be recursive, can be in one line\n",
    "    def classify(self,testExample):\n",
    "        #figure out what attribute the node is\n",
    "        #return that value?\n",
    "        try:\n",
    "            childAttr = self.__childNodes[testExample[self.__attribute]]\n",
    "            return childAttr.classify(testExample)\n",
    "        except:\n",
    "            print \"error\"\n",
    "                \n",
    "        \n",
    "class DLeaf:\n",
    "    \"\"\"represents leaves of a decision tree\"\"\"\n",
    "    def __init__(self,labelVal):\n",
    "        self.__label = labelVal\n",
    "\n",
    "    def printNode(self,numIndents = 0):\n",
    "        for i in range(numIndents): print(\" \"), #print with no newline, this only works for Python 2\n",
    "        print \"LEAF: \"+self.__label\n",
    "\n",
    "    #this method classifies new test data as acc, unacc, good, vgood\n",
    "    def classify(self,testExample):\n",
    "        #want to return prediction -- return unacc/acc/good/vgood -- label keeps track of this\n",
    "        return self.__label    \n",
    "\n",
    "def binData(colName):\n",
    "    newCol = list()\n",
    "    binList = data[colName]\n",
    "    avg = binList.mean()\n",
    "    splitFourths = avg / 4\n",
    "    for x in binList:\n",
    "        if x < splitFourths:\n",
    "            newCol.append(0)\n",
    "        elif x < splitFourths*2:\n",
    "            newCol.append(1)\n",
    "        elif x < splitFourths*3:\n",
    "            newCol.append(2)\n",
    "        else:\n",
    "            newCol.append(3)\n",
    "    return newCol    \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "import pandas\n",
    "import random\n",
    "from sklearn import cross_validation\n",
    "\n",
    "#data = pandas.read_csv('carData.csv')\n",
    "data = pandas.read_csv('german_credit.csv')\n",
    "\n",
    "#this is a disctionary we'll use to keep track of all\n",
    "#possible values that any given attribute can have\n",
    "possibleValuesForEachColumn  = {}\n",
    "\n",
    "#headers = ['price','maint','doors','persons','trunk','safety','acceptability']\n",
    "headers = ['Status of existing checking account', 'Duration in month', 'Credit history','Purpose', 'Credit amount', 'Savings account/bonds', 'Present employment since',\\\n",
    "            'Installment rate in percentage of disposable income', 'Personal status and sex', 'Other debtors / guarantors',  'Present residence since',\\\n",
    "             'Property', 'Age in years','Other installment plans ', 'Housing', 'Number of existing credits at this bank', 'Job', 'Number of people being liable to provide maintenance for',\\\n",
    "                 'Telephone', 'foreign worker',  'Creditability']\n",
    "\n",
    "for h in headers:\n",
    "    possibleValuesForEachColumn[h] = data[h].unique()\n",
    "    \n",
    "cols = ['Credit amount', 'Duration in month', 'Age in years']\n",
    "\n",
    "for x in cols:\n",
    "    data[x] = binData(x)\n",
    "    \n",
    "#10% of the data goes into the test set, the rest into the training set   \n",
    "(trainData, testData) = cross_validation.train_test_split(data,test_size = 0.1) \n",
    "\n",
    "#initialize the root node\n",
    "#t = DNode(trainData,['price','maint','doors','persons','trunk','safety'],possibleValuesForEachColumn,'acceptability')\n",
    "t = DNode(trainData,['Status of existing checking account', 'Duration in month', 'Credit history','Purpose', 'Credit amount', 'Savings account/bonds', 'Present employment since',\\\n",
    "            'Installment rate in percentage of disposable income', 'Personal status and sex', 'Other debtors / guarantors',  'Present residence since',\\\n",
    "             'Property', 'Age in years', 'Other installment plans ','Housing', 'Number of existing credits at this bank', 'Job', 'Number of people being liable to provide maintenance for',\\\n",
    "                 'Telephone', 'foreign worker'],possibleValuesForEachColumn,'Creditability')\n",
    "t.train() #train the whole tree\n",
    "\n",
    "#test if classify function works\n",
    "#t.classify()\n",
    "\n",
    "#once you add the classify() method to the DNode and DLeaf, you can uncomment the following code\n",
    "\n",
    "numCorrect = 0.0\n",
    "for i in range(len(testData)):  #go through all the testing examples\n",
    "    testExample = testData.iloc[i] #current row\n",
    "    prediction = t.classify(testExample) #prediction of current row\n",
    "    if prediction == testExample['Creditability']: #was the prediction correct?\n",
    "        numCorrect += 1.0\n",
    "\n",
    "accuracy = numCorrect/len(testData)\n",
    "print accuracy\n",
    "\n",
    "#t.printNode() #print the tree to see what it looks like\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
